---
date: 2020-12-01 12:26:40
layout: post
title: Docker 101
subtitle: Let's learn Docker together.
description: What is docker and how to learn fast.
image: https://th.bing.com/th/id/Rb3e6202f5356edebd8c8205623eef0f1?rik=2tDqbcLpDFguLg&riu=http%3a%2f%2fwww.shadowandy.net%2fwp%2fwp-content%2fuploads%2fdocker.png&ehk=d2o4OLvE5SZOjrajjCgOCdzXQ9xmehUy6vTEhPPFi3c%3d&risl=&pid=ImgRaw
optimized_image: https://th.bing.com/th/id/Rb3e6202f5356edebd8c8205623eef0f1?rik=2tDqbcLpDFguLg&riu=http%3a%2f%2fwww.shadowandy.net%2fwp%2fwp-content%2fuploads%2fdocker.png&ehk=d2o4OLvE5SZOjrajjCgOCdzXQ9xmehUy6vTEhPPFi3c%3d&risl=&pid=ImgRaw
category: docker
tags:
  - docker
  - devops
author: Shubhendu Shubham
comment: true
---

Before staring Docker containers, let's understand how a team develops and deploy applications.
The process of developing and managing application in a company typically includes one or more teams.There's a development team that creates the software, and an operations team responsible for the deployment of these applications. The operations team is also responsible for the management of the application hosting infrastructure.

## Considerable Challanges :-

1. **Management of hosting environments**

   The different environments all require both software and hardware management. We have to ensure that both the installed software and configured hardware in each is the same. We also need to configure aspects such as network access, data storage, and security per environment in a consistent and easily reproducible manner.

2. **Continuity in software delivery**

   The deployment of applications to our environments must happen consistently. Each deployment package must include all system packages, binaries, libraries, configuration files, and other items that will ensure a fully functional application. We also need to make sure that all of these dependencies match software versions and architecture.

3. **Efficient use of hardware**

   Each deployed application must execute in such a way that it's isolated from other applications running on the same hardware. We aim to run more than one application per server to make the best use of resources without compromising each other.

4. **Application portability**

   There are several reasons why application portability is essential. A hosting environment might fail, or we need to scale out our application. In both instances, the potential result is a redeployment of our software to a new environment. We want to move software from one host to another even if the underlying infrastructure is different. Such a move needs to happen as fast as possible to reduce downtime for our customers.

## What is a container?

A container is a loosely isolated environment that allows us to build and run software packages. These software packages include the code and all dependencies to run applications quickly and reliably on any computing environment. We call these packages container images.

The container image becomes the unit we use to distribute our applications.

## What is software containerization?

Software containerization is an OS virtualization method that is used to deploy and run containers without using a virtual machine (VM). Containers can run on physical hardware, in the cloud, VMs, and across multiple OSs.

## What is Docker?

Docker is a containerization platform used to develop, ship, and run containers. Docker doesn't use a hypervisor, and you can run Docker on your desktop or laptop if you're developing and testing applications. The desktop version of Docker supports Linux, Windows, and macOS. For production systems, Docker is available for server environments, including many variants of Linux and Microsoft Windows Server 2016 and above. Many clouds, including Azure, supports Docker.

## Docker architecture

The Docker platform consists of several components that we use to build, run, and manage our containerized applications.

## Docker Engine

The Docker Engine consists of several components configured as a client-server implementation where the client and server run simultaneously on the same host. The client communicates with the server using a REST API, which allows the client to also communicate with a remote server instance.

![Project file](https://docs.microsoft.com/en-us/learn/modules/intro-to-docker-containers/media/2-docker-architecture.svg "Docker engine")

**The Docker client**

The Docker client is a command-line application named docker that provides us with a command line interface (CLI) to interact with a Docker server. The docker command uses the Docker REST API to send instructions to either a local or remote server and functions as the primary interface we use to manage our containers.

**The Docker server**

The Docker server is a daemon named dockerd. The dockerd daemon responds to requests from the client via the Docker REST API and can interact with other daemons. The Docker server is also responsible for tracking the lifecycle of our containers.

**Docker objects**

There are several objects that you'll create and configure to support your container deployments. These include networks, storage volumes, plugins, and other service objects. We won't cover all of these objects here, but it's good to keep in mind that these objects are items that we can create and deploy as needed.

## Docker Hub

Docker Hub is a Software-as-a-Service (SaaS) Docker container registry. Docker registries are repositories that we use to store and distribute the container images we create. Docker Hub is the default public registry Docker uses for image management.

## How Docker images work

We know that the container image becomes the unit we use to distribute applications. And the container is in a standardized format used by both our developer and operation teams.

so let's look at the differences between software, packages, and images as used in Docker. Knowing the differences between these concepts will help us better understand how Docker images work.

First let's briefly discuss the roles of the OS running on the host and the OS running in the container.

## Software packaged into a container

The software packaged into a container isn't limited to the applications our developers build. When we talk about software, we refer to application code, system packages, binaries, libraries, configuration files, and the operating system running in the container.

## What is a container image?

A container image is a portable package that contains software. It's this image that, when run, becomes our container. The container is the in-memory instance of an image.

A container image is immutable. Once you've built an image, the image can't be changed. The only way to change an image is to create a new image. This feature is our guarantee that the image we use in production is the same image used in development and QA.

## What is the host OS?

The host OS is the OS on which the Docker engine runs. Docker containers running on Linux share the host OS kernel and don't require a container OS as long as the binary can access the OS kernel directly.

![Project file](https://docs.microsoft.com/en-us/learn/modules/intro-to-docker-containers/media/3-container-scratch-host-os.svg "Host Os")

However, Windows containers need a container OS. The container depends on the OS kernel to manage services such as the file system, network management, process scheduling, and memory management.

## What is the container OS?

The container OS is the OS that is part of the packaged image. We have the flexibility to include different versions of Linux or Windows OSs in a container. This flexibility allows us to access specific OS features or install additional software our applications may use.

![Project file](https://docs.microsoft.com/en-us/learn/modules/intro-to-docker-containers/media/3-container-ubuntu-host-os.svg "Container Os")

The container OS is isolated from the host OS and is the environment in which we deploy and run our application. Combined with the image's immutability, this isolation means the environment for our application running in development is the same as in production.

In our example, we're using Ubuntu Linux as the container OS and this OS doesn't change from development or production. The image we use is always the same.

## What is the Stackable Unification File System (Unionfs)?

Unionfs is used to create Docker images. Unionfs is a filesystem that allows you to stack several directories, called branches, in such a way that it appears as if the content is merged. However, the content is physically kept separate. Unionfs allows you to add and remove branches as you build out your file system.

![Project file](https://docs.microsoft.com/en-us/learn/modules/intro-to-docker-containers/media/3-unionfs-diagram.svg "Unionfs")

## What is a base image?

A base image is an image that uses the Docker scratch image. The scratch image is an empty container image that doesn't create a filesystem layer. This image assumes that the application you're going to run can directly use the host OS kernel.

## What is a parent image?

A parent image is a container image from which you create your images.

For example, instead of creating an image from scratch and then installing Ubuntu, we'll rather use an image already based on Ubuntu. We can even use an image that already has Nginx installed. A parent image usually includes a container OS.

## What is the main difference between base and parent images?

Base images allow us more control over the contents of the final image. Recall from earlier that an image is immutable, you can only add to an image and not subtract. Both image types allow us to create a reusable image.

## What is a Dockerfile?

A Dockerfile is a text file that contains the instructions we use to build and run a Docker image. The following aspects of the image are defined:

- The base or parent image we use to create the new image
- Commands to update the base OS and install additional software
- Build artifacts to include, such as a developed application
- Services to expose, such a storage and network configuration
- Command to run when the container is launched

**The Dockerfile may look like the following example.**

```Docker

FROM Ubuntu
RUN apt-get install python3 -y
RUN apt-get install virtualenv -y

RUN pip3 --no-cache-dir install numpy

RUN pip3 install pandas

RUN pip3 install scikit-learn

RUN pip3 install matplotlib

RUN pip3 install pillow

RUN apt-get install python3-pip -y

RUN apt-get install python3-setuptools -y

RUN apt-get install python3-wheel -y
RUN apt-get install pkg-config -yRUN pip3  install tensorflow
RUN pip3 install --upgrade tensorflow-probability
RUN pip3  install keras
RUN apt-get install git -y

RUN apt-get install sudo -y

RUN pip3 install --no-cache-dir install

RUN pip3 install --upgrade setuptools

RUN pip3 install ez_setup

RUN pip3 install --upgrade pip

RUN pip3  install tensorflow
RUN pip3 install --upgrade tensorflow-probability
RUN pip3  install keras
RUN apt-get  install git -y

ENV shubhendu

```

## How to manage Docker images

Docker images are large files that initially get stored on your PC and we need tools to manage these files.

The Docker CLI allows us to manage images by building, listing, removing, and running them. We manage Docker images by using the docker client. The client doesn't execute the commands directly and sends all queries to the dockerd daemon.

## How to build an image

We use the docker build command to build Docker images. Let's assume we use the Dockerfile definition from earlier to build an image. Here is an example that shows the build command.

**Bash**

```Build
docker build -t temp-ubuntu .
```

**Output**

```Output

Sending build context to Docker daemon  4.69MB
Step 1/8 : FROM ubuntu:18.04
 ---> a2a15febcdf3
Step 2/8 : RUN apt -y update && apt install -y wget nginx software-properties-common apt-transport-https && wget -q https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb && dpkg -i packages-microsoft-prod.deb && add-apt-repository universe && apt -y update && apt install -y dotnet-sdk-3.0
 ---> Using cache
 ---> feb452bac55a
Step 3/8 : CMD service nginx start
 ---> Using cache
 ---> ce3fd40bd13c
Step 4/8 : COPY ./default /etc/nginx/sites-available/default
 ---> 97ff0c042b03
Step 5/8 : WORKDIR /app
 ---> Running in 883f8dc5dcce
Removing intermediate container 883f8dc5dcce
 ---> 6e36758d40b1
Step 6/8 : COPY ./website/. .
 ---> bfe84cc406a4
Step 7/8 : EXPOSE 80:8080
 ---> Running in b611a87425f2
Removing intermediate container b611a87425f2
 ---> 209b54a9567f
Step 8/8 : ENTRYPOINT ["dotnet", "website.dll"]
 ---> Running in ea2efbc6c375
Removing intermediate container ea2efbc6c375
 ---> f982892ea056
Successfully built f982892ea056
Successfully tagged temp-ubuntu:latest

```

## Updating OS

```Update
 apt -y update and apt install -y

```

## What is an image tag?

An image tag is a text string that is used to version an image.

## How to list images?

The Docker software automatically configures a local image registry on your machine. You can view the images in this registry with the docker images command.

**Console**

```Image
docker images
```

**Output**

```Output

REPOSITORY          TAG                IMAGE ID            CREATED                SIZE
tmp-ubuntu          latest             f89469694960        14 minutes ago         1.69GB
tmp-ubuntu          version-1.0        f89469694960        14 minutes ago         1.69GB
ubuntu              18.04               a2a15febcdf3       5 weeks ago            64.2MB

```

## How to remove an image

**Code**

```Remove
docker rmi temp-ubuntu:version-1.0
```

## How to manage Docker containers

A Docker container has a lifecycle that you can manage and track the state of the container.

![Project file](https://docs.microsoft.com/en-us/learn/modules/intro-to-docker-containers/media/4-docker-container-lifecycle.svg "Docker Conatiner")

To place a container in the run state, use the run command. You can also restart a container that is already running. When restarting a container, the container receives a termination signal to enable any running processes to shut down gracefully before the container's kernel is terminated.

A container is considered in a running state until it's either paused, stopped, or killed. A container, however, may also exit from the run state by itself. A container can self-exit when the running process completes, or if the process goes into a fault state.

To pause a running container, use the pause command. This command suspends all processes in the container.

To stop a running container, use the stop command. The stop command enables the working process to shut down gracefully by sending it a termination signal. The container's kernel terminates after the process shuts down.

To send a kill signal if you need to terminate the container, use the kill command. The running process doesn't capture the kill signal, only the container's kernel. This command will forcefully terminate the working process in the container.

Lastly, to remove containers that are in a stopped state, use the remove command. After removing a container, all data stored in the container gets destroyed.
